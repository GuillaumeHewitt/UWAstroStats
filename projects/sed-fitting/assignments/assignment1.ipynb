{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f9a492",
   "metadata": {},
   "source": [
    "# Assignment 1 - SED Fitting\n",
    "\n",
    "## Error estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b440d9f8",
   "metadata": {},
   "source": [
    "This assignment is split into 3 sections, roughly corresponding to the contents of each of the 3 weeks in the Error Estimation module\n",
    "\n",
    "The SETUP section is designed to be done first, to familarize yourself with the data and the details of SED fitting. Section 1 is shorter to account for this\n",
    "\n",
    "Feel free to write functions in a separate module and import them here if you like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29cfd0a",
   "metadata": {},
   "source": [
    "# SETUP\n",
    "\n",
    "- Download the data from [here](https://irfu.cea.fr/Pisp/yu-yen.chang/sw.html) (both the input and output catalog). These come from [Chang et al. (2015)](https://ui.adsabs.harvard.edu/abs/2015ApJS..219....8C/abstract)\n",
    "\n",
    "- Install [Prospector](https://github.com/bd-j/prospector) (we found this easiest to do using the [conda script](https://github.com/bd-j/prospector/blob/main/conda_install.sh) provided)\n",
    "\n",
    "- Pick a galaxy in the *input* data (this can be any row with FLAG=1)\n",
    "\n",
    "- Use prospector to fit an SED model (pick any model you like) to your chosen galaxy\n",
    "\n",
    "    - To do this we recommend following the [quickstart guide](https://prospect.readthedocs.io/en/latest/quickstart.html) in the prospector documentation and adapting to our data \n",
    "\n",
    "\n",
    "- Now repeat for a few different galaxies (try to pick a range of magnitudes, redshifts, etc)\n",
    "\n",
    "- Try using a model with a fixed redshift (using the spectroscopic redshift in the catalog) vs fitting the redshift from the photometry\n",
    "\n",
    "########\n",
    "\n",
    "###Do we want to provide a working example for our data?\n",
    "\n",
    "########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f84aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## python assignment_params.py --objid=33 --optimize --emcee --outfile=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc95bdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prospect.io.read_results as reader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13d42248",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'test_24Jan10-12.05_result.h5'\n",
    "res, obs, model = reader.results_from(file_name)\n",
    "results_type = \"emcee\" # | \"dynesty\"\n",
    "randint = np.random.randint\n",
    "\n",
    "sps = reader.get_sps(res)\n",
    "\n",
    "\n",
    "if results_type == \"emcee\":\n",
    "## ANI NOTES you can choose this at random?\n",
    "    \n",
    "    nwalkers, niter = 2, 2\n",
    "    theta = res['chain'][randint(nwalkers), randint(niter)]\n",
    "else:\n",
    "    theta = res[\"chain\"][randint(len(res[\"chain\"]))]\n",
    "\n",
    "imax = np.argmax(res['lnprobability'])\n",
    "\n",
    "if results_type == \"emcee\":\n",
    "    i, j = np.unravel_index(imax, res['lnprobability'].shape)\n",
    "    theta_max = res['chain'][i, j, :].copy()\n",
    "    thin = 5\n",
    "else:\n",
    "    theta_max = res[\"chain\"][imax, :]\n",
    "    thin = 1\n",
    "\n",
    "a = 1.0 + model.params.get('zred', 0.0) # cosmological redshifting\n",
    "# photometric effective wavelengths\n",
    "wphot = obs[\"phot_wave\"]\n",
    "# spectroscopic wavelengths\n",
    "# *restframe* spectral wavelengths, since obs[\"wavelength\"] is None\n",
    "wspec = sps.wavelengths\n",
    "wspec *= a #redshift them\n",
    "xmin, xmax = np.min(wphot)*0.8, np.max(wphot)/0.8\n",
    "initial_spec, initial_phot, initial_mfrac = model.sed(theta, obs=obs, sps=sps)\n",
    "\n",
    "temp = np.interp(np.linspace(xmin,xmax,10000), wspec, initial_spec)\n",
    "ymin, ymax = temp.min()*0.8, temp.max()/0.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fc94db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_spec, initial_phot, initial_mfrac = model.sed(theta, obs=obs, sps=sps)\n",
    "\n",
    "# generate model\n",
    "prediction = model.mean_model(theta, obs=obs, sps=sps)\n",
    "pspec, pphot, pfrac = prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c435a6",
   "metadata": {},
   "source": [
    "# SECTION 1\n",
    "\n",
    "- #### Goodness of fit of Prospector examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df948e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the data for a chosen galaxy (with error bars) \n",
    "### Flux or magnitude vs band wavelength or index\n",
    "\n",
    "### Add the best fit model to the plot\n",
    "\n",
    "### Compute the goodness-of-fit (chi squared)\n",
    "### (Prospector assumes the magnitudes are independent so you can to, but we'll come back to this later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac02d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Is the goodness of fit reasonable (why?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b406ce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### What is the best fit, mean, and 1/2/3 sigma confidence intervals for each of the constrained parameters\n",
    "### Are they consistent with the results from Chang et al (the output file linked above)?\n",
    "### How similar do we expect them to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a63863",
   "metadata": {},
   "outputs": [],
   "source": [
    "### How did allowing the redshift as a free parameter change the results? did you get the same mass? is the redshift correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b7702",
   "metadata": {},
   "source": [
    "# SECTION 2 \n",
    "\n",
    "- #### Covariance of contrained parameters (Gaussian assumption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f9424",
   "metadata": {},
   "outputs": [],
   "source": [
    "### First lets look at the covariance of constrained parameters\n",
    "### Plot a corner plot of the prospector outputs, showing the 68% and 95% 2D contours\n",
    "### (You will want to use one of the MCMC methods in the prospector fitting ...\n",
    "###    we will discuss this more in the MCMC section. For now we can assume that the density of ...\n",
    "###    output samples at a given location in parameter space, is proportional to the probability of ...\n",
    "###    those parameters, given the data and model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9791caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Are there any degeneracies between parameters in the fit?\n",
    "### What does this mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3473e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make a covarinace matrix of the fitted parameters (describing the uncertainties and their covarinace with each other) \n",
    "### Plot it\n",
    "### Looking at the contour plot, was this a reasonable thing to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba23e86",
   "metadata": {},
   "source": [
    "- #### Covariance of magnitude errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461b0146",
   "metadata": {},
   "outputs": [],
   "source": [
    "### So far, prospector has assumed the uncertainties in the magnitudes/fluxes are independent of each other \n",
    "### In practice this might not be true\n",
    "### For this excercise, assume the correlation between the flux in each band is X%\n",
    "### Plot the covariance matrix, with and without the correlated errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ad938",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Re-compute the goodness of fit with the correlated errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed3b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Did the goodness-of-fit get worse or better, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ba85be",
   "metadata": {},
   "source": [
    "# SECTION 3 \n",
    "\n",
    "Estimating error bars and uncertainty of distributions (shot noise, bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8544d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For this section we will use the output catalogs, since running prospector on all \n",
    "### 800000 galaxies would be a waste of computing for this class\n",
    "\n",
    "### Plot a histogram of a given measured quantity (stellar mass, redshift, etc) \n",
    "### Choose the range and bin size appropriately so that we can see the full distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7193a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "### There are a limited number of objects in each histogram bin\n",
    "### Add shot noise (Poisson) to the histogram bars to show this\n",
    "### These with be your \"analytic\" error bars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e16341",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now split the data into N subsets and compute the jackknife covarinace of the histogram bins \n",
    "### How does it compare to the analytic errors\n",
    "### Are the bins independent?\n",
    "### What if you make N very large or very small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc667885",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now repeat this excercise, replacing the histogram with a calculation of the mean stellar \n",
    "### mass as a function of redshift (i.e. Split the data into redshift bins, and compute the mean mass in each)\n",
    "### Use Jackknife to get the errors\n",
    "### How to these compare with the standard error of the mean?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
